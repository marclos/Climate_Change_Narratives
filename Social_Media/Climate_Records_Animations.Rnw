\documentclass{article}
\usepackage{hyperref}
% \usepackage{animate}
<<echo=FALSE, warnings=FALSE, message=FALSE >>=
library(rgdal)
library(tidyverse)
library(plyr)
library(dplyr)
library(rnoaa)
library(ncdf4)
library(magick)
library(animation)
library(xtable)
library(lubridate)
library(ggplot2)
#library(pdftools)
@

<<noaakey, echo=FALSE>>=

# Could a key go bad?  5/9/22, the API stopped working.

options(noaakey = "qZqZPeprQLtooYJMiFzCEqqaNMdGJRgb")
@

\title{Communicating Climate Change with Weather Records}
\author{Marc Los Huertos}

\begin{document}
\maketitle

\section{Evaluating Terrestrial Meteorological Data}

\subsection{Selected History of Climate Science}

Geologists have known the climate has been changing over the Earth's history. But what causes these changes has been a major research area for over 100 years. There are numerous drivers that contribute to changing climates -- including the arrangement of the continents on the planet, the distance to the sun, energy generated by the sun, volanic activity, and the composition of the Earth's atmosphere. 

It's the last one that we'll spend time because the Earth's temperature are changing pretty dramatically over the last 100 years and the cause is no mystery -- the human activity that has released CO2 into the atmosphere. The two main sources of CO2 is from land use change, e.g. deforestration, and the burning of fossil fuels, e.g. coal, oil, and natural gas. 

The first to propose the role of CO2 on the Earth's atmosphere was a Swedish scientist Svante Arrhenius, who figured out that CO2 absorbs infarred light. Moreover, he deduced that the Earth's temperature was actually warmer than it might otherwise be if CO2 was not part of the Earth's atmoshere. 


\subsection{NOAA Data Records}

%ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/v3/

\subsubsection{rNOAA Package and R}

R is an open source programming environment that has become one of the most popular tools for statiticians and data scientists. Capitalizing on the open source framework, a wide range of libraries or packages have been developed to faciliate data processing, analysis, and graphical displays. On such package is rNOAA developed to collect and display climate records stored on NOAA servers.


Using the package requires the use of a key. To maintain the integrity of the key, it's best to avoid posting the key in a public repository and to encryp the key to ensure it's not abused. 

\subsection{Selecting Weather Records by State}

\subsubsection{State Temperature Records}

There are numerous ways to analyze temperature records, where stations can be analyzed individually or records could be sampled and analyzed in spatially in grids. Each of these are valid approaches depending on the question to be addressed. 

In this case the question is ``Based on the longest state meterological record, is there a temperature trend?"

\subsection{Approach}

\subsubsection{List of Cities}

rNOAA has a simple function to list for each of the states and the weather stations in each. We'll use ncdc\_locs() functions to select each state and ncdc\_station() to obtain the station ids with the longest records. 

<<listofstates, results='hide'>>=
# List of States (alpha beta)
ncdc_locs(locationcategoryid='ST', limit=55)

# Alabama 
# ncdc_locs(locationid='FIPS:01', limit=52)
@

The function queries the NOAA website and retrieves state codes, ``FIPS:XX''.  

%NOTE: By default 25 records (cities) are retrieved. See \texttt{?ncdc_locs} to learn how to include arguments to obtain more records.  

NOTE2: It would be nice to make a map of how concentrated the stations spatially. 

%\subsubsection{Getting Data}

\subsubsection{Selection Stations}

With the state ids, we can then, get metadata for all the weather stations, which will work to get the longest records, using \texttt{ncdc\_stations()}. 

First, we subset the data for stations that actively collecting data. Then we'll sort to the active stations to find the one with the longest records. We will use these stations for our analysis. 
<<ncdc_stations, results='hide'>>=

# alabama stations.. sorted by the most recent
# test <- ncdc_stations(datasetid='GHCND', 
# datatypeid = c("TMAX", "TMIN"), locationid='FIPS:01', 
# limit=1000, sortfield = 'maxdate', sortorder='desc')

get_locationid <- function(FIPS){
   fips = ncdc_locs(locationcategoryid='ST', limit=55)
   temp <- data.frame(State = fips$data$name[FIPS], 
             id = fips$data$id[FIPS])
   temp$id <- as.character(temp$id)
   temp$State <- as.character(temp$State)
   return(temp)
}

@
\subsubsection{Select State}

Using the rNOAA function ncdc\_locs(), we can queary NOAA's database to identify station codes (FIPS) by state. With the states and some territories, there are 55 FIPS for US weather stations. 

<<>>=
fips = get_locationid(3); str(fips); 

@

After 

<<selectstation>>=   
GSOM_Stations <- ncdc_stations(datasetid='GSOM', 
               datatypeid = c("TMAX", "TMIN"),
               locationid=fips$id, limit=1000, 
               sortfield = 'maxdate', sortorder='desc')

GSOM_Recent = 
   GSOM_Stations$data[GSOM_Stations$data$maxdate>='2021-11-01',]

GSOM_Coverage = 
   GSOM_Recent[GSOM_Recent$datacoverage > 0.92,]
GSOM_Sorted =  GSOM_Coverage[order(GSOM_Coverage$mindate),]
#GSOM_Longest = 
 #  GSOM_Coverage[GSOM_Coverage$mindate == min(GSOM_Coverage$mindate),]
GSOM_Longest = GSOM_Sorted[1,] #Pick longest
# Second and Third for Comparisons
# GSOM_Longest = GSOM_Sorted[3,] 
# GSOM_Longest = GSOM_Sorted[4,]
@

The record selected has the following metadata associated with it, which will be used for nameing, labeling, and mapping. 

<<echo=FALSE>>=
GSOM_Longest
@

\subsubsection{Download GSOM Data using rnoaa}

<<startyear, echo=FALSE>>=
(startyear=as.numeric(format(as.Date(GSOM_Longest$mindate), 
         format = "%Y")))
@

\subsubsection{Functions to Collect and Clean GSOM}

To collect the data, I used a short function, but the download time is painfully slow because only 1 year can be obtained at a time. Might want to get a work around for this at some point. 

<<getGSOM_function>>=
get_GSOM <- function(stid, datatype) {
   wtr<-list()  # create an empty list
   for (i in startyear:2021) {
      start_date <- paste0(i, "-01-01")
      end_date <- paste0(i, "-12-31")
      
#save data portion to the list (elements named for the year
      wtr[[as.character(i)]] <- ncdc(datasetid='GSOM', 
         stationid=stid, datatypeid=datatype, startdate =
         start_date, enddate = end_date, limit=400)$data
   }
   #return the full list of data frames
   return(wtr)
}

stid = substr(GSOM_Longest$id, 7, 17)

get_GSOM2 <- function(stid){
   http.csv <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
   read.csv(paste(http.csv, stid, ".csv", sep=""))
}

# GSOM <- get_GSOM2(stid)

@

The function relies on two inputs, the station id and the measured parameter -- TMAX and TMIN in this case. After that, the data needs to be clean up quite a bit. 

Furthermore, I have converted units to Farenheit, which is not my favorite, but important for US consumption.

<<getGSOM, warning=FALSE>>=
GSOM_TMAX <- get_GSOM(GSOM_Longest$id, 'TMAX')
GSOM_TMIN <- get_GSOM(GSOM_Longest$id, 'TMIN')
GSOM_PPT  <- get_GSOM(GSOM_Longest$id, 'PRCP')

# Bind the dataframes in the list 
# together into one large dataframe

tbl_TMAX <- dplyr::bind_rows(GSOM_TMAX)
tbl_TMIN <- dplyr::bind_rows(GSOM_TMIN)
tbl_PPT <- dplyr::bind_rows(GSOM_PPT)

class(tbl_TMAX) # [1] "tbl_df"  "tbl" "data.frame"
dfTbl_TMAX = as.data.frame(tbl_TMAX)
dfTbl_TMIN = as.data.frame(tbl_TMIN)
dfTbl_PPT = as.data.frame(tbl_PPT)

class(dfTbl_TMAX) # [1] "data.frame"
dfTbl_TMAX$TMAX = dfTbl_TMAX$value*9/5+32
dfTbl_TMIN$TMIN = dfTbl_TMIN$value*9/5+32
dfTbl_PPT$PPT = dfTbl_PPT$value

dfTbl_TMAX$Date = as.Date(dfTbl_TMAX$date)
dfTbl_TMIN$Date = as.Date(dfTbl_TMIN$date)
dfTbl_PPT$Date = as.Date(dfTbl_PPT$date)

dfTbl_TMAX <- subset(dfTbl_TMAX, select=c(Date, station, TMAX))
dfTbl_TMIN <- subset(dfTbl_TMIN, select=c(Date, TMIN))
dfTbl_PPT <- subset(dfTbl_PPT, select=c(Date, PPT))

dfTbl_TMAX[1,]

GSOM <- merge(dfTbl_TMAX, dfTbl_TMIN, by="Date")
GSOM <- merge(GSOM, dfTbl_PPT, by="Date")

GSOM$Month = as.numeric(format(as.Date(GSOM$Date), format = "%m"))
GSOM$Year = as.numeric(format(as.Date(GSOM$Date), format = "%Y"))
GSOM$Decade = floor_decade(GSOM$Year)

str(GSOM)
@

\subsubsection{Function to Evaluate Monthy Trends}

Function to evaluate each month and determine if there is a trend. At somepoint, I'll have to the stats correcting for the autocorrelation. 

<<Monthly_summarystats, eval=FALSE, echo=FALSE>>=
# find most important month
sumstats = NA
for (m in 1:12){
  TMIN.lm = lm(TMIN~Date, GSOM[GSOM$Month==m,])
  TMAX.lm = lm(TMAX~Date, GSOM[GSOM$Month==m,])
   PPT.lm  = lm(PPT~Date, GSOM[GSOM$Month==m,])

 sumstats = rbind(sumstats, 
   data.frame(Month = m, Param="TMIN", Slope = coef(TMIN.lm)[2], 
   r2 = summary(TMIN.lm)$r.squared, p_value= anova(TMIN.lm)$'Pr(>F)'[1]),
   data.frame(Month = m, Param="TMAX", Slope = coef(TMAX.lm)[2], 
   r2 = summary(TMAX.lm)$r.squared, p_value= anova(TMAX.lm)$'Pr(>F)'[1]),
   data.frame(Month= m, Param="PPT", Slope = coef(PPT.lm)[2], 
   r2 = summary(PPT.lm)$r.squared, p_value= anova(PPT.lm)$'Pr(>F)'[1]))

} #end loop

sumstats=data.frame(sumstats)[-1,]
rownames(sumstats)<-NULL
head(sumstats)
## Determine Months with Biggest Slopes
# I should probably look at all months for pos and neg slopes.

#TMINmonth = sumstats$Month[sumstats$TMIN_Slope == max(sumstats$TMIN_Slope, na.rm=T)]
#TMAXmonth = sumstats$Month[sumstats$TMAX_Slope == max(sumstats$TMAX_Slope, na.rm=T)]
#PPTMINmonth = sumstats$Month[sumstats$PPT_Slope == min(sumstats$PPT_Slope, na.rm=T)]
#PPTMAXmonth = sumstats$Month[sumstats$PPT_Slope == max(sumstats$PPT_Slope, na.rm=T)]

head(sumstats)

# Select Months with Changes

#TMIN = subset(sumstats, select=c(Month, TMIN_Slope, TMIN_r2, TMIN_p_value),  subset = Month==TMINmonth);  names(TMIN)=c("Month", "Slope", "r2", "p_value");  TMIN$param = "TMIN"

#TMAX = subset(sumstats, select=c(Month, TMAX_Slope, TMAX_r2, TMAX_p_value), subset = Month==TMAXmonth); names(TMAX)=c("Month", "Slope", "r2", "p_value"); TMAX$param = "TMAX"

#PPTMIN = subset(sumstats, select=c(Month, PPT_Slope, PPT_r2, PPT_p_value), subset = Month==PPTMINmonth); names(PPTMIN)=c("Month", "Slope", "r2", "p_value"); PPTMIN$param = "PPTMIN"

#PPTMAX = subset(sumstats,  select=c(Month, PPT_Slope, PPT_r2, PPT_p_value), subset = Month==PPTMAXmonth); names(PPTMAX)=c("Month", "Slope", "r2", "p_value"); PPTMAX$param = "PPTMAX"

#sumstats2 <- rbind(TMIN, TMAX, PPTMIN, PPTMAX)

sumstats$Symbol = ""
sumstats$Symbol[sumstats$p_value < 0.05] = "*"
sumstats$Symbol[sumstats$p_value < 0.01] = "**"
sumstats$Symbol[sumstats$p_value < 0.001] = "***"

sumstats
#TMAX.pvalues <- subset(sumstats, TMAX_p_value <.05, 
#           select=c(Month, TMAX_p_value))
#TMAX.pvalues$Symbol = "*"
#TMAX.pvalues$Symbol[TMAX.pvalues$TMAX_p_value < 0.01] = "**"
#TMAX.pvalues$Symbol[TMAX.pvalues$TMAX_p_value < 0.001] = "***"

#TMAX.pvalues
@

Evaluate both TMAX and TMIN in GSOM by Year using MonthEvalStats() function. 
<<EvaluationMonthlyTrends>>=
MonthEvalStatsOLD <- function(GSOM) {
sumstats = NA
for (m in 1:12){
  TMIN.lm = lm(TMIN~Date, GSOM[GSOM$Month==m,])
  TMAX.lm = lm(TMAX~Date, GSOM[GSOM$Month==m,])
   PPT.lm  = lm(PPT~Date, GSOM[GSOM$Month==m,])

 sumstats = rbind(sumstats, 
   data.frame(Month = m, Param="TMIN", Slope = coef(TMIN.lm)[2], 
   r2 = summary(TMIN.lm)$r.squared, p_value= anova(TMIN.lm)$'Pr(>F)'[1]),
   data.frame(Month = m, Param="TMAX", Slope = coef(TMAX.lm)[2], 
   r2 = summary(TMAX.lm)$r.squared, p_value= anova(TMAX.lm)$'Pr(>F)'[1]),
   data.frame(Month= m, Param="PPT", Slope = coef(PPT.lm)[2], 
   r2 = summary(PPT.lm)$r.squared, p_value= anova(PPT.lm)$'Pr(>F)'[1]))

}

sumstats=data.frame(sumstats)[-1,]
rownames(sumstats)<-NULL

sumstats$Symbol = ""
sumstats$Symbol[sumstats$p_value < 0.05] = "*"
sumstats$Symbol[sumstats$p_value < 0.01] = "**"
sumstats$Symbol[sumstats$p_value < 0.001] = "***"
sumstats[,c(7,9)]
return(sumstats)
}

MonthEvalStats <- function(GSOM) {
sumstats = NA
for (m in 1:12){
  TMIN.lm = lm(TMIN~Date, GSOM[GSOM$Month==m,])
  TMAX.lm = lm(TMAX~Date, GSOM[GSOM$Month==m,])
   PPT.lm  = lm(PPT~Date, GSOM[GSOM$Month==m,])

 sumstats = rbind(sumstats, 
   data.frame(Month = m, Param="TMIN", Slope = coef(TMIN.lm)[2], 
   r2 = summary(TMIN.lm)$r.squared, p_value= anova(TMIN.lm)$'Pr(>F)'[1]),
   data.frame(Month = m, Param="TMAX", Slope = coef(TMAX.lm)[2], 
   r2 = summary(TMAX.lm)$r.squared, p_value= anova(TMAX.lm)$'Pr(>F)'[1]),
   data.frame(Month= m, Param="PPT", Slope = coef(PPT.lm)[2], 
   r2 = summary(PPT.lm)$r.squared, p_value= anova(PPT.lm)$'Pr(>F)'[1]))

} #end loop

sumstats=data.frame(sumstats)[-1,]
rownames(sumstats)<-NULL
head(sumstats)

sumstats$Symbol = ""
sumstats$Symbol[sumstats$p_value < 0.05] = "*"
sumstats$Symbol[sumstats$p_value < 0.01] = "**"
sumstats$Symbol[sumstats$p_value < 0.001] = "***"
return(sumstats)
}

# test function
sumstats = MonthEvalStats(GSOM[500:4000,])
@

\subsubsection{Function to report Probabilities}

<<report_prob_fun, results='hide'>>=
report_prob <-function(pvalue){
   if(pvalue > 0.05) return("> 0.05 (Not Significant)")
   if(pvalue < 0.05 & pvalue >= 0.001) return(
      paste("=", round(pvalue, 3), "(Statistically Significant)"))
   #if(pvalue < 0.01) print(round(pvalue, 4))
   if(pvalue < 0.001) return("< 0.001 (Statisically Significant)")
}

#test function
report_prob(0.0032)

report_prob2 <-function(lm){
   # lm=GSOM.lm
   if(anova(lm)$'Pr(>F)'[1] > 0.05){
         return("p-value > 0.05 (Not Significant)")
      }
   if(anova(lm)$'Pr(>F)'[1] < 0.05 & 
      anova(lm)$'Pr(>F)'[1] >= 0.001){
         return(paste("Change ", round(coef(lm)[2]*356.25*100, 1), 
         "/100 years, ", "p-value =", round(anova(lm)$'Pr(>F)'[1], 3), 
         "(Statistically Significant)", sep=""))
      }
   if(anova(lm)$'Pr(>F)'[1] < 0.001) {
         return(paste("Change ", round(coef(lm)[2]*325.25*100, 1), 
         "/100 years, ", "p-value < 0.001 (Statistically Significant)", 
         sep=""))
   }
}

report_prob3 <-function(lm){
   #lm=Drought.run.lm
   temp = data.frame(change = NA, p_value=NA, note=NA)
   if(anova(lm)$'Pr(>F)'[1] > 0.05){
      temp[,1] <- "";
      temp[,2] <- "p-value > 0.05";
      temp[,3] <- "(Not Significant)"
      return(temp)
      }
   if(anova(lm)$'Pr(>F)'[1] < 0.05 & 
      anova(lm)$'Pr(>F)'[1] >= 0.001){
      temp[,1] <- paste("Change: ", round(coef(lm)[2]*356.25*100, 1), "°F/100 years", sep=""); 
      temp[,2] <- paste("p-value = ", round(anova(lm)$'Pr(>F)'[1], 3), sep="");
      temp[,3] <- " (Statistically Significant)"
      return(temp)
      }
   if(anova(lm)$'Pr(>F)'[1] < 0.001) {
      temp[,1] <- paste("Change: ", round(coef(lm)[2]*356.25*100, 1), "°F/100 years", sep=""); 
      temp[,2] <- "p-value < 0.001";
      temp[,3] <- " (Statistically Significant)"
      return(temp)
   }
}
@

\section{Communicating Long-term Weather Records}

\subsection{Total Records and Post 1975 Records}

<<>>=
setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Social_Media")
png(paste0("png//", fips$State, "-", stid, "-GSOMmonthly.png"), width = 480, height = 320, units = "px", pointsize = 12, bg = "white")
par(las=1, mfrow=c(1,1))
plot(TMAX~Date, GSOM, pch=20, cex=.5, col="grey", ylab="°F")
GSOM.lm = lm(TMAX~Date, GSOM)
pred_dates <-data.frame(Date = GSOM$Date); 
nrow(pred_dates);# pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="gray50")

# Post 1975
GSOM.lm = lm(TMAX~Date, GSOM[GSOM$Year>1975,])
pred_dates <-data.frame(Date = GSOM$Date[GSOM$Year>1975]); 
nrow(pred_dates); #pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="red")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")
location_index = round(length(GSOM[GSOM$Year>1975,]$Date) * 0.99,0)
text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob3(GSOM.lm))[2], pos=2, cex=1.0, col="red")
#abline(coef(lm(TMAX~Date, GSOM)), col="black")
#abline(coef(lm(TMAX~Date, GSOM[GSOM$Year>1975,])), col="red")
dev.off()
@

The noise in the data suggest that there is no trend, but it's tricky because the seasonal variation dominates the source of varition. Is there a way to "filter" out the seasonal effect?

\subsection{Filtering Seasonal Effect}

Method 1 Filtering by Monthly Mean 

<<GSOM_Anomaly>>=

TMAX.Monthly.means = aggregate(TMAX~Month, data=GSOM, mean)
names(TMAX.Monthly.means)=c("Month", "TMAXmean")
GSOM2 = merge(GSOM, TMAX.Monthly.means, by="Month")
GSOM2$TMAX.anom = GSOM2$TMAX - GSOM2$TMAXmean

TMIN.Monthly.means = aggregate(TMIN~Month, GSOM, mean)
names(TMIN.Monthly.means)=c("Month", "TMINmean")
GSOM2 = merge(GSOM2, TMIN.Monthly.means, by="Month")
GSOM2$TMIN.anom = GSOM2$TMIN - GSOM2$TMINmean

# Sort by date
GSOM2 <- GSOM2[order(GSOM2$Date),]
@

<<>>=
png(paste0("png//", fips$State, "-", stid, "-GSOM-anomoly.png"), width = 480, height = 320, units = "px", pointsize = 12, bg = "white")
par(las=1, mfrow=c(1,1))
par(las=1)
plot(TMAX.anom~Date, GSOM2, pch=20, cex=.5, col="grey", ylab="Max. Temp (anomaly) °F", main=paste0(fips$State, " (", stid, ")", report_prob3(GSOM.lm)[3]))
GSOM.lm = lm(TMAX.anom~Date, GSOM2)
pred_dates <-data.frame(Date = GSOM2$Date); 
nrow(pred_dates); #pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="gray50")

ymax=max(GSOM2$TMAX.anom) - (max(GSOM2$TMAX.anom)-min(GSOM2$TMAX.anom))*.3
ymax2 <- ymax - (max(GSOM2$TMAX.anom)-min(GSOM2$TMAX.anom))*.1

location_index = round(length(GSOM2[GSOM2$Year>1975,]$Date) * 0.99,3)
text(pred_dates$Date[location_index], ymax, 
     paste(report_prob3(GSOM.lm))[1], pos=2, cex=.9)
text(pred_dates$Date[location_index], ymax2, 
     paste(report_prob3(GSOM.lm))[2], pos=2, cex=.9)

# Post 1975
GSOM.lm = lm(TMAX.anom~Date, GSOM2[GSOM2$Year>1975,])
pred_dates <-data.frame(Date = GSOM2$Date[GSOM2$Year>1975]); 
nrow(pred_dates); #pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="red")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")

ymax=max(GSOM2$TMAX.anom) - (max(GSOM2$TMAX.anom)-min(GSOM2$TMAX.anom))*.7
ymax2 <- ymax - (max(GSOM2$TMAX.anom)-min(GSOM2$TMAX.anom))*.1

location_index = round(length(GSOM2[GSOM2$Year>1975,]$Date) * 0.99,0)
text(pred_dates$Date[location_index], ymax, 
     paste(report_prob3(GSOM.lm))[1], pos=2, cex=.9, col="red")
text(pred_dates$Date[location_index], ymax2, 
     paste(report_prob3(GSOM.lm))[2], pos=2, cex=.9, col="red")
dev.off()
@

%"png//", fips$State, "-", stid, "-GSOM-anomoly.png"

And to see what we created, see Figure~\ref{fig:GSOM-anomaly}.
\begin{graphic}
\includegraphics[width=1.00\textwidth]{\Sexpr{paste0("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Social_Media/png/", fips$State, "-", stid, "-GSOM-anomaly.png")}}
\caption{The changing in monthly temperature data.}
\label{fig:GSOM-anomaly}
\end{graphic}

\subsubsection{Polynomial Filter}

<<>>=
# fit polynomial: x^2*b1 + x*b2 + ... + bn

# create time series object
#X = [i%365 for i in range(0, len(series))]
# y = series.values

# degree = 4
#coef = polyfit(X, y, degree)
# print('Coefficients: %s' % coef)
# create curve

@


\subsection{Tables Temp Trends}

Admittedly, determining the months with the biggest changes isn't a very good approach for hypothesize testing -- it's more like a fishing expedition, but as long as we understand the difference between an a priori hypothesis and an exploratory analysis, we should be okay if we make appropriate conclusions. 

<<EvaluatingMonthDelta>>=
# Selecting Most Important Monthly Changes (TMAX overwrites)
#sumstats = MonthEvalStats(GSOM)

TMIN_Increase_month = with(sumstats[sumstats$Param=="TMIN",], 
     Month[Slope==max(Slope, na.rm=T)])
TMIN_Decrease_month = with(sumstats[sumstats$Param=="TMIN",], 
     Month[Slope==min(Slope, na.rm=T)])
TMAX_Increase_month = with(sumstats[sumstats$Param=="TMAX",], 
     Month[Slope==max(Slope, na.rm=T)])
TMAX_Decrease_month = with(sumstats[sumstats$Param=="TMAX",], 
     Month[Slope==min(Slope, na.rm=T)])
PPT_Increase_month = with(sumstats[sumstats$Param=="PPT",], 
     Month[Slope==max(Slope, na.rm=T)])
PPT_Decrease_month = with(sumstats[sumstats$Param=="PPT",], 
     Month[Slope==min(Slope, na.rm=T)])
@
\subsubsection{Month with Biggest Changes}

Minimum temperature (TMIN) changes, as one way to avoid bias, I am looking at the upward or downward changes in minimum temperatures, even though we expect warmer temperatures, while the power of the tests is lower.  
<<echo=FALSE, results='asis'>>=
sumstats$Slope100 = sumstats$Slope*100
TMIN.xtbl <- xtable(sumstats[sumstats$Param=="TMIN", c(1,7,4:6)], digits=c(0,0,4,2,4,3), caption="Caption TMIN")

print(TMIN.xtbl, type="latex", comment=FALSE)

@

TMAX
<<echo=FALSE, results='asis'>>=
sumstats$Slope100 = sumstats$Slope*100
TMAX.xtbl <- xtable(sumstats[sumstats$Param=="TMAX", c(1,7,4:6)], digits=c(0,0,4,2,4,3), caption="Caption TMAX")

print(TMAX.xtbl, type="latex", comment=FALSE)
@

PPT changes are tricky to capture.

<<echo=FALSE, results='asis'>>=
sumstats$Slope100 = sumstats$Slope*100
PPT.xtbl <- xtable(sumstats[sumstats$Param=="PPT", c(1,7,4:6)], digits=c(0,0,4,2,4,3), caption="Caption PPT")

print(PPT.xtbl, type="latex", comment=FALSE)

#tmp <- tempfile()
#options(xtable.comment=FALSE)  ## removes the nasty comments
#capture.output(PPT.xtbl, file=tmp)
#rmarkdown::render(tmp, output_format="pdf_document", output_file="deleteme.pdf")
#unlink(tmp)
#pdftools::pdf_convert("deleteme.pdf", format="png")
@




\subsection{Functions to Collect and Clean CHCND}

CHCND have been bias corrected...

<<CHCND_Download>>=
GSOM_Longest$id

stid = substr(GSOM_Longest$id, 7, 17)

CHCND.https <- "https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/"

get_CHCND <- function(stid) {
   #stid = "USC00013511"
   import <- read.csv(paste(CHCND.https, stid, ".csv", sep=""))
   selected = subset(import, select=c("DATE", "TMAX", "TMIN", "PRCP"))
   selected$TMAX = selected$TMAX/10*(9/5)+32
   selected$TMIN = selected$TMIN/10*(9/5)+32
   selected$Date = as.Date(selected$DATE)
   selected = selected[complete.cases(selected$TMAX),]
   selected
}

CHCND <- get_CHCND(stid); nrow(CHCND)
#str(CHCND)



CHCND$Month = as.numeric(format(as.Date(CHCND$Date), format = "%m"))
CHCND$Month.name = factor(format(as.Date(CHCND$Date), format = "%b"),
         levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul",
                     "Aug", "Sep", "Oct", "Nov", "Dec"))
#levels(CHCND$Month.name)

range(CHCND$TMAX, na.rm=T)
spread = sd(CHCND$TMAX, na.rm=T)*4
TMAX_mean = mean(CHCND$TMAX, na.rm=T)

CHCND$TMAX[complete.cases(CHCND$TMAX) & 
              CHCND$TMAX > TMAX_mean+spread] <-NA
CHCND$TMAX[complete.cases(CHCND$TMAX) & 
              CHCND$TMAX < TMAX_mean-spread] <-NA
range(CHCND$TMAX, na.rm=T)

CHCND$Year = as.numeric(format(as.Date(CHCND$Date), format = "%Y"))
CHCND$YearDay = CHCND$Year + yday(CHCND$Date)/366
head(CHCND)
@

\subsection{Extreme Events}

\subsubsection{Functions for Rainfall Trends}

Rainfall trends are tough. Exteme events can occur in 24 hours or over long periods that might result in floods or droughts. Each region might have different patterns, so developing a consistent approach is tough.

We can look for trends in monthly averages, number of days without rain (important in tropics), and/or extreme events based on daily or hourly data. 

I don't know of a robust way to look at this for the entire globe. 

<<<>>=
CHCND$Season = "Winter"
CHCND$Season[CHCND$Month==4 | CHCND$Month==5 | CHCND$Month==6] = "Spring"
CHCND$Season[CHCND$Month==7 | CHCND$Month==8 | CHCND$Month==9] = "Summer"
CHCND$Season[CHCND$Month==10 | CHCND$Month==11 | CHCND$Month==12] = "Fall"


PRCP.Total = aggregate(PRCP~Year, data=CHCND, sum, na.rm=T)
PRCP.Season.Total = aggregate(PRCP~Season+Year, data=CHCND, sum, na.rm=T)
@

<<>>=
ggplot( ) +
   geom_point(data = CHCND, 
      aes(y=PRCP, x=YearDay), size=.05, color="gray") + 
   geom_bar(data = PRCP.Total, 
      aes(x=Year, y=PRCP), stat="identity", 
      position="identity") + 
   xlim(min(CHCND$Year), max(CHCND$Year)-1) 
   #ylab("Number of Extreme Temps") + # for the y axis label

@

<<>>=
ggplot( ) +
   geom_bar(data = PRCP.Season.Total, 
      aes(x=Year, y=PRCP, fill=Season), stat="identity") + 
         xlim(min(CHCND$Year), max(CHCND$Year)-1) +
   #ylab("Number of Extreme Temps") + # for the y axis label
   geom_smooth(data = PRCP.Total, 
      aes(y=PRCP, x=Year), method = "lm", 
      se = T, color= "black") 

# + geom_smooth(data= PRCP.Season.Total, aes(x=Year, y = PRCP, color = Season, group=Season), se=F)
@

Days without rain...within a calendar year... bleed over between years isn't captured..

<<>>=
CHCND$PRCP.count = sequence(rle(CHCND$PRCP)$lengths)
Drought.run.temp <- data.frame(Year = NA, lengths=NA, values=NA)
for(i in min(CHCND$Year):max(CHCND$Year)){
   # print(i)
   run.length = rle(CHCND[CHCND$Year==i,]$PRCP)
   run.length.df = data.frame(Year = rep(i, length(run.length$values)), 
         lengths = run.length$lengths,
         values = run.length$values)
   
   Drought.run.temp <- rbind(Drought.run.temp, 
         run.length.df[run.length.df$values==0,])
}
Drought.run <- Drought.run.temp[-1,]
str(Drought.run)
names(Drought.run)

# What is a drought 10 days, 20 days, 40 days?

Drought.run.10 = aggregate(lengths~Year, 
   data=Drought.run[Drought.run$lengths>=10,], sum)
Drought.run.20 = aggregate(lengths~Year, 
   data=Drought.run[Drought.run$lengths>=20,], sum)
Drought.run.40 = aggregate(lengths~Year, 
   data=Drought.run[Drought.run$lengths>=40,], sum)
Drought.run.100 = aggregate(lengths~Year, 
   data=Drought.run[Drought.run$lengths>=100,], sum)

plot(lengths~Year, Drought.run.10, pch=20, cex=.5)
points(lengths~Year, Drought.run.20, pch=20, col="blue", cex=.5)
points(lengths~Year, Drought.run.40, pch=20, col="red", cex=.5)
points(lengths~Year, Drought.run.100, pch=20, col="purple", cex=.5)

abline(lm(lengths~Year, Drought.run.10))
abline(lm(lengths~Year, Drought.run.20), col="blue")
abline(lm(lengths~Year, Drought.run.40), col="red")
abline(lm(lengths~Year, Drought.run.100), col="purple")
summary(lm(lengths~Year, Drought.run.100))


plot(lengths~Year, Drought.run[Drought.run$lengths>30,], pch=20)
plot(lengths~Year, Drought.run[Drought.run$lengths>30,], pch=20)


Drought.run.lm <- lm(lengths~Year, Drought.run[Drought.run$lengths>10,])
summary(Drought.run.lm)
text(min(Drought.run$Year, na.rm=T), max(Drought.run$lengths, na.rm=T), 
     paste("Slope (x100) = ", round(coef(Drought.run.lm)[2]*100, 3)), pos=4)
#plot(PRCP.count ~ Year, data=CHCND[CHCND$PRCP==0,])

@

Probability Distributions by decade...

<<>>=

floor_decade <- function(value){ 
   return(value - value %% 10) }
floor_decade(c(1883,1988))

CHCND$Decade <- floor_decade(CHCND$Year)

PRCP.Decade <- aggregate(PRCP~Month+Decade, data=CHCND, sum)
head(PRCP.Decade)

x <- PRCP.Decade$PRCP[PRCP.Decade$Decade==1900]
df <- approxfun(density(x))
plot(1:12, density(x))
xnew <- c(0.45,1.84,2.3)
points(xnew,df(xnew),col=2)

@


\subsection{Determine Record Setting Temperatures}

In many cases, people seem to "feel" how temperature has been changing over time, and new records seem to capture the attention in the media. So, we'll create a updated record of maximum temperatures and display them. 

<<extremetempplot, echo=FALSE, results='hide'>>=

CHCND$mmdd <- format(CHCND$Date, "%m-%d")
CHCND_Mean = mean(CHCND$TMAX, na.rm=T)

CHCND$maxTMAX <- CHCND$minTMIN <- NA

for(i in 1:nrow(CHCND)){
   if(is.na(CHCND$TMAX[i])) next
   
   CHCNDmmdd <- CHCND$mmdd[i] # Index Correct Day/Month to compare
   CHCND$maxTMAX[i] <- CHCND$TMAX[i] # Assign value to maxTMAX

   if(CHCND$TMAX[i] < 
      max(CHCND$TMAX[CHCND$mmdd==CHCNDmmdd], na.rm=T) ){ 
      CHCND$maxTMAX[i] <- NA} else
      {
      CHCND$maxTMAX[i] <- CHCND$TMAX[i]
      }
}


for(i in 1:nrow(CHCND)){
   if(is.na(CHCND$TMIN[i])) next
   
   CHCNDmmdd <- CHCND$mmdd[i] # Index Correct Day/Month to compare  
   CHCND$minTMIN[i] <- CHCND$TMIN[i] # Assign value to mintMIN

   if(CHCND$TMIN[i] > 
      min(CHCND$TMIN[CHCND$mmdd==CHCNDmmdd], na.rm=T) ){ 
      CHCND$minTMIN[i] <- NA} else
      {
      CHCND$minTMIN[i] <- CHCND$TMIN[i]
      }
 }
head(CHCND)
@

Crating a graphic of the results...
<<testplot_noeval, echo=FALSE, eval=FALSE>>=
for(i in seq(min(CHCND$Year), max(CHCND$Year), by=2)){
 # i=min(CHCND$Year)
   plot(TMAX~Date, CHCND[CHCND$Year<=i,], pch='.', col="grey80")
   points(maxTMAX~Date, data=CHCND[CHCND$Year<=i,], 
          pch=20, col="red", cex=.8 )
}
@

\subsubsection{Number of Days with Records per year}

This is a common way to communicate temperatures changes. I suspect we have a better sense of change when we notice "extreme" events...

<<>>=
names(CHCND)

minTMIN.length = aggregate(minTMIN~Year, data=CHCND, length)
minTMIN.length$group <- "Record Lows"
names(minTMIN.length) <- c("Year", "Num", "Group")
minTMIN.length$Num = -minTMIN.length$Num

maxTMAX.length = aggregate(maxTMAX~Year, data=CHCND, length); 
maxTMAX.length$group <- "Record Highs"
names(maxTMAX.length) <- c("Year", "Num", "Group")

records = rbind(minTMIN.length, maxTMAX.length); # records


ggplot( ) +
   geom_point(data = CHCND, aes(y=TMIN, x=YearDay), size=.05, color="gray") + 
   geom_bar(data = records, aes(x=Year, y=Num, fill=Group), stat="identity", position="identity") + 
   xlim(min(CHCND$Year), max(CHCND$Year)-1) +
   #ylab("Number of Extreme Temps") + # for the y axis label
   scale_fill_manual("Legend", values = c("Record Highs" = "red", "Record Lows" = "blue")) +
   geom_smooth(data = CHCND, aes(y=TMIN, x=YearDay), method = "lm", se = FALSE)
   
   
#scale_y_continuous(
    # Features of the first axis
    # name = "Temperature (F °)",
    # Add a second axis and specify its features
    # sec.axis = sec_axis(~.*Num, name="Number of Extreme Temps")
  #) 

@

\subsection{Iterate TMAX vs. Month Boxplots}

<<boxplots, eval=FALSE, echo=FALSE>>=
for(i in min(CHCND$Year+5):max(CHCND$Year)){
  # i=1930
CHCNDsub = subset(CHCND, CHCND$Year<=i, 
                  select=c(Month, Month.name, TMAX, TMIN))

boxplot(TMAX ~ Month.name, data=CHCNDsub, 
        main=paste("Maximum Daily Temperatures", min(CHCND$Year), "-",
                   i, GSOM_Longest$name),
   sub="(NOTE: Red astrisks with signfic. changes)")

symbol.y = (par()$yaxp[2])-diff(par()$yaxp[1:2])*.99
#symbol.y = (par()$yaxp[2])
text(sumstats$Month, symbol.y, sumstats$TMAX_Symbol, col="red", cex=2)
}
@

\section{Static Plot Results}

\subsection{Static Plots}

To test the code, I have created graphics that can then be used in the animation process, i.e. try to create code that doesn't get too complicated and then fail! 

<<static_template, eval=TRUE, echo=FALSE>>=
setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Social_Media")
png(paste0("png//", fips$State, "-", stid, "-GSOM.png"), width = 480, height = 480, units = "px", pointsize = 12, bg = "white")
#png(paste0("png//Rplot_", i, ".png"), width = 480, height = 480, units = "px", pointsize = 12, bg = "white")
#------------------------------------

ylim_new=NA
for(i in seq(min(GSOM$Year), max(GSOM$Year), by=2)) 
   {
par(las=1, mfrow=c(4,1), mar= c(4, 4, 2, 1) + 0.1)
   GSOMsub <- GSOM[GSOM$Month==maxmonth & GSOM$Year<=i,]
   if(nrow(GSOMsub)<10) next
plot(TMIN~Date, GSOMsub[GSOMsub$Month==maxmonth,], 
   col='gray70', pch=20, xlab="", 
   main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
              "Min. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMIN~Date, GSOMsub)
pred_dates <-data.frame(Date = GSOMsub$Date); 
nrow(pred_dates); pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")
location_index = round(length(GSOMsub$Date) * 0.99,0)
text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2, cex=1.5)

# Box Plot of TMAX by Month -------------------------------
CHCNDsub = subset(CHCND, CHCND$Year<=i, 
      select=c(Month, Month.name, TMAX, TMIN))
boxplot(TMAX ~ Month.name, data=CHCNDsub, main="")
symbol.y = (par()$yaxp[2])-diff(par()$yaxp[1:2])*.99
#symbol.y = (par()$yaxp[2])
text(sumstats$Month, symbol.y, sumstats$TMAX_Symbol, 
     col="red", cex=2)
mtext(paste("Maximum Daily Temperatures", min(CHCND$Year), 
      "-", i, GSOM_Longest$name), line=1)
mtext("(NOTE: Red astrisks correspond to signficant changes)", 
      line=0, cex=.7)

# TMAX --------------------------------
ylim = range(GSOMsub$TMAX)
#if(!is.na(ylim_new)) ylim[2]=ylim_new
plot(TMAX~Date, GSOMsub, col='gray70', pch=20, xlab="",
     ylim=ylim,
     main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
                "Max. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMAX~Date, GSOMsub) 

ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")

text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2, cex=1.5)

plot(TMAX~Date, CHCND[CHCND$Year<=i,], pch='.', col="grey80", 
     main="Recorded Daily High Temperatures")
points(maxTMAX~Date, data=CHCND[CHCND$Year<=i,], pch=20, 
       col="red", cex=.8 )
}

#----------------------------------------------------
dev.off()
@


\subsection{Temp \& Precipitation Probability}

To highlight the patterns of change, it might be useful to analyze how the probability ditributuion might change -- we can use a normal probability distribion as a theoretical distribution (and we can check if this distribuion is approrpriate with a Chi-Square test), or we can use the data to create a emperical distribution, which is my favored approach.

<<>>=
TMAX.mean.anomaly.decade = aggregate(TMAX.anom ~ Decade, GSOM2, mean)
TMAX.sd.anomaly.decade = aggregate(TMAX.anom ~ Decade, GSOM2, sd)

names(TMAX.sd.anomaly.decade)=c("Decade", "TMAX.sd.anom")

TMIN.mean.anomaly.decade = aggregate(TMIN.anom ~ Decade, GSOM2, mean)
TMIN.sd.anomaly.decade = aggregate(TMIN.anom ~ Decade, GSOM2, sd)

names(TMIN.sd.anomaly.decade)=c("Decade", "TMIN.sd.anom")

TMAX.temp = merge(TMAX.mean.anomaly.decade, TMAX.sd.anomaly.decade, by="Decade")

TMIN.temp = merge(TMIN.mean.anomaly.decade, TMIN.sd.anomaly.decade, by="Decade")

GSOM.Monthly.Anom.mean.sd = merge(TMAX.temp, TMIN.temp, by="Decade")

Anom.x = seq(min(GSOM2$TMAX.anom), max(GSOM2$TMAX.anom),by=.1)

plot(Anom.x, dnorm(Anom.x, mean=GSOM.Monthly.Anom.mean.sd$TMAX.anom[1]), ty="l", col="blue", ylab="Density")
lines(Anom.x, dnorm(Anom.x, mean=GSOM.Monthly.Anom.mean.sd$TMAX.anom[4]), col="green")
lines(Anom.x, dnorm(Anom.x, mean=GSOM.Monthly.Anom.mean.sd$TMAX.anom[14]), col="red")

library(densEstBayes)
#hist(OldFaithful2011,col = "gold",main = "",probability = TRUE, xlab = "time interval between geyser eruptions (minutes)")

#destSMFVB <- densEstBayes(OldFaithful2011,method = "SMFVB")

#plot(destSMFVB,xlab = "time interval between geyser eruptions (minutes)", main = "method = \"SMFVB\" (semiparametric mean field variatiodestNUTS <- densEstBayes(OldFaithful2011, method = "NUTS")

#plot(destNUTS,xlab = "time interval between geyser eruptions (minutes)", main = "method = \"NUTS\" (no-U-turn sampler)")

@


\section{Animated GIFs}

So far, this creates a gif file, but I haven't been able get the gif in the pdf directly yet. I will need an additional package or create separate png that are combined. For now, we'll create a gif file to be used in separate documents.

\subsection{Animated Probability Distributions}

<<animate, results='hide', eval=TRUE>>=

# Define an image_graph size
img <- image_graph(600, 480, res = 96) 
# START ------------------------------------------

ylim_new=NA
for(i in 1:length(unique(GSOM2$Decade))) 
   {
# i = 9
decade=(unique(GSOM2$Decade))[order(unique(GSOM2$Decade))==i]

GSOM2sub <- GSOM2[GSOM2$Decade==decade,]
h.ramp <- rev(heat.colors(length(unique(GSOM2$Decade))+1))[-1]
   
# Determine Stats for PDFs
TMAX.mean.anomaly.decade = aggregate(TMAX.anom ~ Decade, GSOM2sub, mean)
TMAX.sd.anomaly.decade = aggregate(TMAX.anom ~ Decade, GSOM2sub, sd)
names(TMAX.sd.anomaly.decade)=c("Decade", "TMAX.sd.anom")
TMIN.mean.anomaly.decade = aggregate(TMIN.anom ~ Decade, GSOM2sub, mean)
TMIN.sd.anomaly.decade = aggregate(TMIN.anom ~ Decade, GSOM2sub, sd)
names(TMIN.sd.anomaly.decade)=c("Decade", "TMIN.sd.anom")

TMAX.temp = merge(TMAX.mean.anomaly.decade, TMAX.sd.anomaly.decade, by="Decade")

TMIN.temp = merge(TMIN.mean.anomaly.decade, TMIN.sd.anomaly.decade, by="Decade")

GSOM.Monthly.Anom.mean.sd = merge(TMAX.temp, TMIN.temp, by="Decade")

par(las=1, mfrow=c(1,2), mar= c(4, 4, 2, 1) + 0.1)

Anom.x = seq(min(GSOM2$TMAX.anom), max(GSOM2$TMAX.anom), by=.1)
plot(Anom.x, dnorm(Anom.x, mean=GSOM.Monthly.Anom.mean.sd$TMAX.anom[1], sd=GSOM.Monthly.Anom.mean.sd$TMAX.sd.anom[1]), ty="l", col=h.ramp[i], ylab="Density", xlab="TMAX Anomaly")
abline(v=mean(GSOM2$TMAX.anom[GSOM2$Decade==min(GSOM$Decade)]))
mtext(paste0(fips$State, " ", decade), side=3)

Anom.x = seq(min(GSOM2$TMIN.anom), max(GSOM2$TMIN.anom), by=.1)
plot(Anom.x, dnorm(Anom.x, mean=GSOM.Monthly.Anom.mean.sd$TMIN.anom[1], sd=GSOM.Monthly.Anom.mean.sd$TMIN.sd.anom[1]), ty="l", col=h.ramp[i], ylab="Density", xlab="TMIN Anomaly")
abline(v=mean(GSOM2$TMIN.anom[GSOM2$Decade==min(GSOM$Decade)]))
mtext(paste0(fips$State, " ", decade), side=3)
}

par(las=1, mfrow=c(1,2), mar= c(4, 4, 2, 1) + 0.1)
TMAX.anomaly.decade = aggregate(TMAX.anom ~ Decade, GSOM2, FUN = function(x) c(mean = mean(x), sd = sd(x)))
TMIN.anomaly.decade = aggregate(TMIN.anom ~ Decade, GSOM2, FUN = function(x) c(mean = mean(x), sd = sd(x)))


Anom.x = seq(min(GSOM2$TMIN.anom), max(GSOM2$TMIN.anom), by=.1)
plot(Anom.x, dnorm(Anom.x, mean=TMIN.anomaly.decade$TMIN.anom[[1,1]], sd=TMIN.anomaly.decade$TMIN.anom[[1,2]]), ty="l", col=h.ramp[1], ylab="Density", xlab="TMIN Anomaly")
mtext(paste0(fips$State, " ", decade), side=3)
for(i in 2:nrow(TMIN.anomaly.decade)){
lines(Anom.x, dnorm(Anom.x, mean=TMIN.anomaly.decade$TMIN.anom[[i,1]], sd=TMIN.anomaly.decade$TMIN.anom[[i,2]]), col=h.ramp[i])
}
abline(v=mean(GSOM2$TMIN.anom[GSOM2$Decade==min(GSOM$Decade)]), col="blue")
abline(v=mean(GSOM2$TMIN.anom[GSOM2$Decade==max(GSOM$Decade)]), col="red")

Anom.x = seq(min(GSOM2$TMAX.anom), max(GSOM2$TMAX.anom), by=.1)
plot(Anom.x, dnorm(Anom.x, mean=TMAX.anomaly.decade$TMAX.anom[[1,1]], sd=TMAX.anomaly.decade$TMAX.anom[[1,2]]), ty="l", col=h.ramp[1], ylab="Density", xlab="TMAX Anomaly")
mtext(paste0(fips$State, " ", decade), side=3)
for(i in 2:nrow(TMAX.anomaly.decade)){
lines(Anom.x, dnorm(Anom.x, mean=TMAX.anomaly.decade$TMAX.anom[[i,1]], sd=TMAX.anomaly.decade$TMAX.anom[[i,2]]), col=h.ramp[i])
}
abline(v=mean(GSOM2$TMAX.anom[GSOM2$Decade==min(GSOM$Decade)]), col="blue")
abline(v=mean(GSOM2$TMAX.anom[GSOM2$Decade==max(GSOM$Decade)]), col="red")


# END -----------------------------------------------------
dev.off()
@


The file is saved in the main directory. 

<<print_img>>=
#print(img)
@

<<write_img, eval=TRUE>>=
GSOM_animation <- image_animate(img, fps = 1, loop=2, optimize = TRUE)
#print(GSOM_animation)
setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/docs/")
image_write(GSOM_animation, paste("Climate_gifs/", fips$State, "-", stid, "_GSOM-ePDF.gif", sep=""))
@




\subsection{4 Plots}

<<animate, results='hide', eval=TRUE>>=

img <- image_graph(600, 480, res = 96)
# START ------------------------------------------

ylim_new=NA
for(i in seq(min(GSOM$Year), max(GSOM$Year), by=2)) 
   {
par(las=1, mfrow=c(4,1), mar= c(2, 4, 2, 1) + 0.1)
   GSOMsub <- GSOM[GSOM$Month==maxmonth & GSOM$Year<=i,]
   if(nrow(GSOMsub)<10) next
plot(TMIN~Date, GSOMsub[GSOMsub$Month==maxmonth,], 
   col='gray70', pch=20, xlab="", 
   main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
              "Min. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMIN~Date, GSOMsub)
pred_dates <-data.frame(Date = GSOMsub$Date); 

#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
#   str(ci)
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")

location_index = round(length(GSOMsub$Date) * 0.99,0)

text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2)

# Box Plot of TMAX by Month -------------------------------
CHCNDsub = subset(CHCND, CHCND$Year<=i, 
                  select=c(Month, Month.name, TMAX, TMIN))

boxplot(TMAX ~ Month.name, data=CHCNDsub, 
        main="")
symbol.y = (par()$yaxp[2])-diff(par()$yaxp[1:2])*.99
#symbol.y = (par()$yaxp[2])
text(sumstats$Month, symbol.y, sumstats$TMAX_Symbol, 
     col="red", cex=2)
mtext(paste("Maximum Daily Temperatures", min(CHCND$Year), 
      "-", i, GSOM_Longest$name), line=1)
mtext("(NOTE: Red astrisks correspond to signficant changes)", 
      line=0, cex=.7)

# TMAX --------------------------------

ylim = range(GSOMsub$TMAX)
#if(!is.na(ylim_new)) ylim[2]=ylim_new
plot(TMAX~Date, GSOMsub, col='gray70', pch=20, xlab="",
     ylim=ylim,
     main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
                "Max. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMAX~Date, GSOMsub) 

ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")

text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2)

plot(TMAX~Date, CHCND[CHCND$Year<=i,], pch='.', col="grey80", 
     main="Recorded Daily High Temperatures")
points(maxTMAX~Date, data=CHCND[CHCND$Year<=i,], pch=20, 
       col="red", cex=.8 )
print(nrow(pred_dates))#; pred_dates
}

# END -----------------------------------------------------
dev.off()
@


The file is saved in the main directory. 

<<print_img>>=
#print(img)
@

<<write_img, eval=TRUE>>=
GSOM_animation <- image_animate(img, fps = 1, loop=2, optimize = TRUE)
#print(GSOM_animation)
setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/docs/")
image_write(GSOM_animation, paste("Climate_gifs/", fips$State, "-", stid, "_GSOM.gif", sep=""))
@


\subsection{KISS}

Keeping it simple is critical in communicating scientific information. In this section, I try to come up with a consistent message for every state and a simple graphic. 

First, TMAX and TMIN -- TMAX trend, TMIN and TMAX histogram, plus PPT?



<<KISS, eval=TRUE, echo=FALSE>>=
setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Social_Media")
png(paste0("png//", fips$State, "-", stid, "-KISS.png"), width = 480, height = 480, units = "px", pointsize = 12, bg = "white")
#png(paste0("png//Rplot_", i, ".png"), width = 480, height = 480, units = "px", pointsize = 12, bg = "white")
#------------------------------------

ylim_new=NA
for(i in seq(min(GSOM$Year), max(GSOM$Year), by=2)) 
   {
par(las=1, mfrow=c(3,1), mar= c(2, 4, 2, 1) + 0.1)
# Box Plot of TMAX by Month -------------------------------
CHCNDsub = subset(CHCND, CHCND$Year<=i, 
      select=c(Month, Month.name, TMAX, TMIN))
boxplot(TMAX ~ Month.name, data=CHCNDsub, main="")
symbol.y = (par()$yaxp[2])-diff(par()$yaxp[1:2])*.99
#symbol.y = (par()$yaxp[2])
text(sumstats$Month, symbol.y, sumstats$TMAX_Symbol, 
     col="red", cex=2)
mtext(paste("Maximum Daily Temperatures", min(CHCND$Year), 
      "-", i, GSOM_Longest$name), line=1)
mtext("(NOTE: Red astrisks correspond to signficant changes)", 
      line=0, cex=.7)


GSOMsub <- GSOM[GSOM$Month==maxmonth & GSOM$Year<=i,]
   if(nrow(GSOMsub)<10) next

# TMIN
plot(TMIN~Date, GSOMsub[GSOMsub$Month==maxmonth,], 
   col='gray70', pch=20, xlab="", 
   main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
              "Min. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMIN~Date, GSOMsub)
pred_dates <-data.frame(Date = GSOMsub$Date); 
nrow(pred_dates); pred_dates
#Predits the values with confidence interval 
ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")
location_index = round(length(GSOMsub$Date) * 0.99,0)
text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2, cex=1.6)


# TMAX --------------------------------
ylim = range(GSOMsub$TMAX)
#if(!is.na(ylim_new)) ylim[2]=ylim_new
plot(TMAX~Date, GSOMsub, col='gray70', pch=20, xlab="",
     ylim=ylim,
     main=paste("Mean", format(GSOMsub$Date,"%B")[1], 
                "Max. Temp", GSOM_Longest$name))
GSOM.lm = lm(TMAX~Date, GSOMsub) 

ci <- predict(GSOM.lm, newdata = pred_dates, 
              interval = 'confidence')
lines(pred_dates$Date, as.numeric(ci[,1]), col="darkred")
lines(pred_dates$Date, as.numeric(ci[,2]), col="darkorange")
lines(pred_dates$Date, ci[,3], col="darkorange")

text(pred_dates$Date[location_index], ci[location_index,3], 
     paste(report_prob2(GSOM.lm)), pos=2, cex=1.6)
}

#----------------------------------------------------
dev.off()
@

\subsection{Show Map of Location}

<<>>=
library(ggmap)
#API = "AIzaSyBfkMN5PYsB0A92RbOxo1bc51y-5aitKDI"
#register_google(key = API, write = TRUE)
#ggmap(myMap)+
#geom_point(aes(x = locus[1], y = locus[2]),
 #alpha = .5, color="darkred", size = 3)

GSOM_Longest$name

lat = GSOM_Longest$latitude
lon = GSOM_Longest$longitude
station = c(lon, lat)
station.df <- data.frame(lon = GSOM_Longest$longitude, 
                         lat = GSOM_Longest$latitude, 
                         Station = GSOM_Longest$name); 
str(station.df)

myMap <- get_map(location=station, zoom=7, scale =2, 
source="stamen", maptype="terrain", messaging = FALSE, crop=FALSE)

ggmap(myMap) + geom_point(aes(x = lon, y = lat), 
      data = station.df, alpha = .5, color="darkred", size = 3) +
      geom_text(aes(x = lon, y = lat, label=Station), 
      data = station.df, alpha = .5, color="darkred", size = 3, 
      hjust=.1, vjust=-1)

#zoom = 11, scale = 2, maptype ='watercolor',

png(paste0("png//", fips$State, "-", stid, "-MAP.png"), 
    width = 480, height = 480, units = "px", 
    pointsize = 12, bg = "white")
ggmap(myMap)+
geom_point(aes(x = lon, y = lat), data = station.df, 
   alpha = .5, color="darkred", size = 3) + 
   geom_text(aes(x = lon, y = lat, label=Station), 
      data = station.df, alpha = .5, color="darkred", 
      size = 3, hjust=.1, vjust=-1)
dev.off()
@

<<eval=FALSE>>=
#A) Download the main crime incident dataset

incidents= read.csv('https://raw.githubusercontent.com/lgellis/MiscTutorial/master/ggmap/i2Sample.csv', stringsAsFactors = FALSE)

#B) Download the extra dataset with the most dangerous Seattle cities as per:

# https://housely.com/dangerous-neighborhoods-seattle/

n <- read.csv('https://raw.githubusercontent.com/lgellis/MiscTutorial/master/ggmap/n.csv', stringsAsFactors = FALSE)

# Look at the data sets

dim(incidents)
head(incidents)
attach(incidents)

dim(n)
head(n)
attach(n)

# Create some color variables for graphing later
col1 = "#011f4b"; col2 = "#6497b1"; col3 = "#b3cde0"; col4 = "#CC0000"

#add year to the incidents data frame
incidents$ymd <-mdy_hms(Event.Clearance.Date)
incidents$year <- year(incidents$ymd)

#Create a more manageable data frame with only 2017 and 2018 data
i2 <- incidents %>% filter(year>=2017 & year<=2018)

#Only include complete cases
i2[complete.cases(i2), ]

#create a display label to the n data frame (dangerous neighbourhoods)
n$label <-paste(Rank, Location, sep="-")

##1) Create a map with all of the crime locations plotted.

p <- ggmap(get_googlemap(center = c(lon = -122.335167, lat = 47.608013),
                    zoom = 11, scale = 2,
                    maptype ='terrain',
                    color = 'color'))
p + geom_point(aes(x = Longitude, y = Latitude,  colour = Initial.Type.Group), data = i2, size = 0.5) + theme(legend.position="bottom")
@



\subsection{OLD version}
<<eval=FALSE, echo=FALSE>>=
library(magick)
#setwd("/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/docs/Social_Media/gif")

#par(las=1, mfrow=c(2,1), mar= c(2, 4, 2, 1) + 0.1)
img <- image_graph(600, 480, res = 96)

for(i in min(GSOM$Year+5):max(GSOM$Year)) {
#png(paste0("png//Rplot_", i, ".png"), width = 480, height = 480, units = "px", pointsize = 12, bg = "white")
   GSOMsub <- GSOM[GSOM$Year<=i,]
par(las=1, mfrow=c(2,1), mar= c(2, 4, 2, 1) + 0.1)
plot(TMIN~Date, GSOMsub[GSOMsub$Month==maxmonth,], col='gray50', pch=20, xlab="")
GSOM.lm = lm(TMIN~Date, GSOMsub[GSOMsub$Month==maxmonth,]) 
abline(coef(GSOM.lm), col='red')
#summary(GSOM.lm); anova(GSOM.lm)$'Pr(>F)'[1]
plot(TMAX~Date, GSOMsub[GSOMsub$Month==maxmonth,], col='gray50', pch=20, xlab="")
GSOM.lm = lm(TMAX~Date, GSOMsub[GSOMsub$Month==maxmonth,]) 
abline(coef(GSOM.lm), col='red')
#summary(GSOM.lm); 
text(i, coef(GSOM.lm)[2]*i+coef(GSOM.lm)[1], paste("p-value", round(anova(GSOM.lm)$'Pr(>F)'[1], 4)))
}

dev.off()
@

<<eval=FALSE, echo=FALSE>>=
GSOM_animation <- image_animate(img, fps = 1, optimize = TRUE)
print(GSOM_animation)

image_write(GSOM_animation, "GSOM.gif")
@

\section{ Other attempts...}

<<eval=FALSE>>=

ncdc_locs(locationcategoryid='CITY', sortfield='name', 
          sortorder='desc')

# ncdc_locs(locationcategoryid='CITY', 
#  locationid='FIPS:01', sortfield='name', sortorder='desc')

#ncdc_datasets(locationcategoryid='CITY', 
#   locationid='FIPS:01', sortfield='name', sortorder='desc')


out <- ncdc(datasetid='NORMAL_DLY', stationid='GHCND:USW00014895', 
            datatypeid='dly-tmax-normal', startdate = '2010-05-01', 
            enddate = '2010-05-10')
@

<<eval=FALSE, echo=FALSE>>=
with_units <- ncdc(datasetid='GHCND', stationid='GHCND:USW00014895', 
                   datatypeid='PRCP', startdate = '2010-05-01', 
                   enddate = '2010-10-31', limit=500, add_units = TRUE)
head( with_units$data )
@
<<>>=
with_units <- ncdc(datasetid='GHCND', stationid='GHCND:USW00014895', 
                   datatypeid='TMAX', startdate = '2010-05-01', 
                   enddate = '2010-10-31', limit=500, add_units = TRUE)
head( with_units$data )
@

<<eval=FALSE, echo=FALSE>>=
ncdc_plot(with_units, breaks="45 days")
@
\subsection{Evaluating Records}

TBD

\subsection{Export Options}

TBD

\section{Sea Surface Temperature Data -- SURP PROJECT WAITING TO HAPPEN}

In contrast to terrestrial data, sea surface temperature (SST) is quite difficult to obtain and process. There are numerous tools to access the data, but they often require knowledge of complex software tools that are not easy to set up or programming experience with python or others.

\url{https://climexp.knmi.nl/select.cgi?id=someone@somewhere&field=ersstv5}

There are, however, a few tools build for R users that seem to accomplish all that we need. 

\url{https://rda.ucar.edu/index.html?hash=data_user&action=register}

\url{https://rda.ucar.edu/datasets/ds277.9/}

Alternatively, we can download flat ascII tables of gridded data:

\url{https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/}


<<echo=TRUE, eval=FALSE>>=

library(chron)
library(RColorBrewer)
library(lattice)
#library(ncdf)
library(ncdf4)
#library(greenbrown) # for gridded trend analysis

ersst.nc = "/home/CAMPUS/mwl04747/github/Climate_Change_Narratives/Data/FA19/ersst.v5.185401.nc"
Y1854 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1854.asc"
Y1864 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1864.asc"
Y1874 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1874.asc"
Y1884 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1884.asc"
Y1894 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1894.asc"
Y1904 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1904.asc"
Y1914 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1914.asc"
Y1924 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1924.asc"
Y1934 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1934.asc"
Y1944 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1944.asc"
Y1954 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1954.asc"
Y1964 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1964.asc"
Y1974 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1974.asc"
Y1984 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1984.asc"
Y1994 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.1994.asc"
Y2004 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.2004.asc"
Y2014 = "https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/ascii/ersst.v5.2014.asc"

temp = rbind(read.table(Y1854)[75,67], read.table(Y1864)[75,67], read.table(Y1874)[75,67],
read.table(Y1884)[75,67], read.table(Y1894)[75,67], read.table(Y1904)[75,67],
read.table(Y1914)[75,67], read.table(Y1924)[75,67], read.table(Y1934)[75,67],
read.table(Y1944)[75,67], read.table(Y1954)[75,67], read.table(Y1964)[75,67],
read.table(Y1974)[75,67], read.table(Y1984)[75,67], read.table(Y1994)[75,67],
read.table(Y2004)[75,67], read.table(Y2014)[75,67])

temp.df = data.frame(Temp = as.vector(temp)/100); temp.df
temp.df$Year = seq(1854, 2014, 10)
plot(Temp~ Year, temp.df)
abline(coef(lm(Temp~Year, data=temp.df)), col="red")
#automating this process!

directory = "/pub/data/cmb/ersst/v5/ascii"

B195401 = nc_open(ersst.nc)


# str(B195401)
# print(B195401)

ncin = B195401

print(ncin)
lon <- ncvar_get(ncin, "lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin, "lat", verbose = F)
nlat <- dim(lat)
head(lat)

print(c(nlon, nlat))

t <- ncvar_get(ncin, "time")
tunits <- ncatt_get(ncin, "time", "units")
nt <- dim(t); nt

lat.sel = 67; lon.set = 75

#ncvar_get(ncin, sst) #object 'sst' not found

#ncvar_get(ncin, var$sst) object of type 'closure' is not subsettable
#ncvar_get(ncin, var) second argument to ncvar_get must be an object of type ncvar or ncdim (both parts of the ncdf object returned by nc_open()), the character-string name of a variable or dimension or NA to get the default variable from the file.  If the file is netcdf version 4 format and uses groups, then the fully qualified var name must be given, for example, model1/run5/Temperature

ncvar_get(ncin, "sst") #spits out the temperatures. but why the negative numbers!

# tmp.array <- ncvar_get(ncin, dname) # doesn't work...

tmp.array <- ncvar_get(ncin, "sst")
dim(tmp.array)

tmp.array[75, 67]

tmp.array[67,]

dlname <- ncatt_get(ncin, "sst", "long_name")
dunits <- ncatt_get(ncin, "sst", "units")
fillvalue <- ncatt_get(ncin, "sst", "_FillValue")
dim(tmp.array)

title <- ncatt_get(ncin, 0, "title")
institution <- ncatt_get(ncin, 0, "institution")
datasource <- ncatt_get(ncin, 0, "source")
references <- ncatt_get(ncin, 0, "references")
history <- ncatt_get(ncin, 0, "history")
Conventions <- ncatt_get(ncin, 0, "Conventions")

# split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth = as.integer(unlist(tdstr)[2])
tday = as.integer(unlist(tdstr)[3])
tyear = as.integer(unlist(tdstr)[1])
chron(t, origin = c(tmonth, tday, tyear))

# tmp.array[tmp.array == fillvalue$value] <- NA

# length(na.omit(as.vector(tmp.array[, , 1])))

m <- 1
tmp.slice <- tmp.array[, , m]

image(lon, lat, tmp.array, col = rev(brewer.pal(10, "RdBu")))

# image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))


@

\section{Satellite Data}

TBD

\section{Ice-Core Data}

TBD



\end{document}